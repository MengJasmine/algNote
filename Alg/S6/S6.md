## Heap & Graph Hashmap
1. Recursion
   - 自上向下：先办事在call，往往call到leaf node的null终止，同时从root到leaf的path上，办事所得到的result要带着往下call，往往return的是void
   - 自下向上：先call后办事，往往是那种需要知道子树信息才能得到当前node的相关知识时，自下向上得到最下面的信息，自下向上返值
2. O(n)时间把n size问题转换成一个n/2 size问题，时间复杂度O(n)，e.g. quick selection
3. O(1)时间，把n size问题劈成两个n/2 size问题，时间复杂度O(n)，e.g. merge sort中的divide
4. Heap
   - Size: 决定heap各种操作的时间复杂度
   - Priority: 大小比较的基准，改写comparator function
   - 使用priorityqueue实现
   - 两个结构：
     - 逻辑结构：complete binary tree
     - 存储结构：unsorted array，即上面的complete binary tree进行level order traverse之后得到的array
   - 6个性质：
     - heap order：
       - Min heap, Max heap，上下有序
       - 对于every node，每个node是以该node为根节点的subtree的最大/小值
       - 因此判断是否是heap order，只要比较当前node和左右left和right的val，因为left和right是各个子树的最大/小值
     - complete binary tree:
       - level order traverse的过程中不会出现null
       - 如果已知当前node在存储结构array中的index，可以O(1)时间得到左右child和其parent的index
     - given an element with index x in the unsorted array
       - parent: (x - 1)/2
       - left child: 2x + 1
       - right child: 2x + 2
     - Heap只能access top node when using it，也就是API来源于queue，只有peek, offer, poll
     - Available API for CRUD operation:
       - insert(put/offer/add): 把新的值插在最后，由于不符合heap逻辑结构，要进行precolate up操作，即和parent相比较，不符合上下有序，则parent和插入值交换，同时继续和再上一层的parent比较看是否符合上下有序，因此最worst情况是一路交换到root，一共logn层，所以时间复杂度是O(logn)
       - get, O(1) 只能get heap顶部
       - update：在heap中，无法update任意位置的val！只能是删掉顶部的，在插入新的，这个过程即为poll+insert，所以也是O(logn)，而这个过程并不常用，所以在priorityqueue没有类似的update
       - delete(pop/poll/remove): 由于priorityqueue性质，heap只支持删除顶部操作，因此整个poll的过程是：
         - get出顶部的element；
         - 把存储结构的最后的element的val赋值到顶部的val
         - 把存储结构中的最后element删除
         - 然后对顶部新的root做precolate down，如果和左右child不符合上下有序，把左右child相对更符合（max heap即为左右child比较大的那个，min heap则是左右child比较小的那个）的和当前交换
         - 交换到新的地方继续和新的下面的左右child进行比较，以此类推
         - 由于最worst情况也是直接换到最下层，也是logn的时间复杂度
     - Heapify：把一个unsorted array，变成符合heap逻辑结构的unsorted array
   - heap在java中的实现```Queue<Student> heap = new PriorityQueue<>();```
     - 如果不传入comparator function:
       - 默认是Min heap！要用Max heap也要传入改写的comparator
       - 如果heap里放的是object，比较是基于reference地址
       - 如果是int，则是基于int的大小比较
     - comparator vs comparable：
       - 以heap举例，heap中放入object
         - 每个object有默认的comparable function，即地址，heap不传入任何comparator的话基于比较的就是reference地址。object可以override comparable function，也就是自己定义什么是“大”，什么是“小”
         - comparator是个object，可以把user defined的comparator传入到heap中（或者别的要自定义比较的class中），然后comparator有个compare function，是传入两个object，return 一个int， 1或者-1说明这两个object哪个大哪个小（return 0则是相等）。所以我们要override这个compare function来实现自定义。通常要把三种情况即什么时候return -1，1，和0都要写，有时候当是user defined一个max heap，直接就是return value2 - value1，对应于正负情况即可
5. Hashmap, hashtable, hashset区别
   - hashset只放一个unique key，hashmap和hashtable放的是key value pair
   - hashtable线程安全，hashmap非线程安全
   - hashtable有synchronize加锁机制保证线程安全，加锁在大量access的情况下会很影响速度，所以一般用hashmap
   - hashset:
     - 使用Set interface声明，HashSet创建，```Set<Integer> set = new HashSet<>();```
     - ```set.contains(key)``` 判断set中是否含有当前key
     - ```set.add(key)```：return boolean, if addable return true and __add it to the hashset__; if not addable return false。兼具判断hashset中是否存在和不存在加入的两个功能
     - ```set.remove(key)```
     - 上述三个crud操作时间复杂度都是O(1)
     - 关于Hashset的object查重：
      ```java
      int[] array1 = new int[] {1, 2}
      int[] array2 = new int[] {1, 2}
      set.add(array1), set.add(array2)

      List<Integer> list1 = new ArrayList<>(); {1,2}
      List<Integer> list2 = new ArrayList<>(); {1,2}
      set.add(list1), set.add(list2)
      ```
     - 上述一个array，一个list，当add array时，hashset比较的是两个array的reference，所以尽管两个array都是{1, 2}，但是内存地址不一样，所以都能add进去；而当add的是两个list时，由于list这个改写了comparable的compare函数，也就是比较的不是默认的地址，而是list的具体内容，所以第二个{1, 2}是加不进去的
   - HashMap:
     - 4个性质：
       - O(1)的CRUD操作，hashmap本质的value是存储在array中，通过hash function （hash code）计算出key所对应的index，找寻到在array中的value
       - hash function设计，key均匀映射稳定的固定的无规律的唯一的value，从bucket（key）到capacity（value）一一映射
         - 最简单的取余，不是consistent hash
         - consistent hash：在大量pair时，增减server尽量减少数据迁移量
         - rehashing: 当load factor过大，需要增加capacity，要重新设计hash function，使得key均匀映射到新的大的array中
         - MD5，SHA-1，SHA-2
       - hash collision：无法设计完美的hash collision，size是有限的！
           - load factor：使用的位置除以总的capacity
           - load factor较高，hash collision很难避免；反之，则说明hash function设计有问题
           - 如何解决？
             - separate chaining：一个key经过hash function得到多个value，把多个value合并成linked list，每个node存储key和value所wrap成的object，hash成一个位置则把value接在这个linked list之后。get时，从linked list头结点遍历寻找当前的key，找到返回对应object中的value。这里如果hash function设计的很不好，所有n个pair都映射到一个位置，则get时间复杂度是O(n)的
             - Open address：没有collision，正常hash function往里放。当发生hash collision，对应位置被占，则向后找，可以linear probing，也可以exponential probing，找空位，找到则把发生collision的pair放在这个新的空的位置。get时，同样先hash到发生collision的原初位置，然后做放pair进去的probing，linear probing或者exponential probing，直到找寻到pair。如果是上述这样，put最差情况就是hash到第一个位置，结果只有最后位置是available，一路找寻n size的capacity；而get同理，先hash到第一个位置，一路找寻到最后一个位置才找到target。当load capacity比较高的时候，linear probing会极巨恶化
             - ![fig6-1](fig6-1.png)
       - 所以设计hashmap时，尽量保证pair的总量低于hash的size的75%，尽可能避免hash collision
     - 使用map interface声明，使用HashMap进行创建，```Map<key, value> map = new HashMap<>();```
     - key必须是unique，value不一定，所以一般说一一对应，其实也是多一对应（多unique key对应相同的value）
     - 只能表示key 到 value单向的对应关系（类似数学中的function），无法表示双向对应关系
     - ```map.containsKey(key)```（同时还有个```map.containsValue(value)```，不用是因为时间复杂度高）。```map.containsKey(key)```的时间复杂度是O(1)，直接通过hash function找到
     - ```map.put(key, value)```，兼具create和update功能，如果没有key，则create这个key value pair，同时return null；如果存在相同的key，则把这个key的valueupdate成输入的value，把覆盖掉的那个原始的value return出来
     - ```map.get(key)```把这个key所对应的value拿出来，如果没有这个key，则return null，注意这里无法区别是key不存在的情况和这个key本身对应那个value就是null的情况。同理，这里null本身也可以作为hashmap的key
     - ```map.remove(key)```
     - 这里上面这4个API的时间复杂度都是O(1)
     - hashmap可以一多对应关系，key对应一个list of value，一个list of object也是可以的
     - 关于改写已经存在hashmap中value的问题：
       - 注意如果是改写hashmap中key对应的value，如果改写的是value本身，需要把它get出来，改写好在put进去
       - 如果改写的是value这个object中的field，可以get然后dereference其field，直接改写其field就可以
       - e.g. map存的是int，```map.get(key) += 1;```；map存的是object```map.get(key).age += 1```。后者可以，前者不行！因为前面get出来的是Integer，这里Integer是primitive type （int）所对应的wrapper是immutable，所以加一之后存到别的内存地址，而由于没有重新put回去，所以map中的value没有更新！
     - 限时即焚，有个key value pair，给定时间，例如10分钟，10分钟可以通过key get到value，10分钟过了就get不到了
       - ```hashmap <key, object(string, expireTime)>```，value是个wrap string内容和expireTime的一个object
         - 第一次get，把expire time改成距离当前时间10分钟后
         - 每次get看expiretime，如果没超过，则继续get
         - 超过了，不能get，同时把这个key value pair删除
       - followup可以是只能get一次，即阅后即焚；也可以是get一次时间刷新，即延时即焚，只要距离上次get不到10分钟，则依然可以get，否则不行
         - 阅后即焚：第一次get之后直接删除这个key value pair
         - 延时即焚: 也就是每次get出来put回去时候把expire time更新下即可
6. Graph
   - 6个性质：
     - graph由nodes和edges组成
     - graph有connected和non-connected区别，连通？
     - graph有directed和弄-directed的edge，有向无向？
     - graph有cycle？
     - graph的edge有无weight？
     - graph的degree，入度：多少指向该node；出度：多少指出该node？合起来是degree
   - 在java如何表示graph？
      ```java
      class GraphNode {
         int value;
         ArrayList<GraphNode> neighs;
         // ArrayList<WeightedEdge> neighs; weighted edge
         // Map<GraphNode> weights;

         GraphNode(int x) {
            value = x;
            neighs = new ArrayList<GraphNode>();
         }
      }

      class WeightedEdge {
         GraphNode neighs;
         int weight;
      }
      ```                     
      - 这里value是node存的值，neighs用来表示边。
      - 有向无向也可以通过neighs表达，a指向b，a的neighs有b，b的neighs没a，则可以a单向指向b。（想象tree
      - 边的weight，也就是edge到weight的pair关系，可以将其wrap成一个object WeightedEdge；也可以用hashmap，注意这个hashmap是每个node都有一个，因为edge需要两个node确定的，hashmap的key是neighs，value是weight，表示当前node到这个neighs的weight
     - 使用matrix表示graph
       - row和col是所有node
       - row，col所在的val表示row到col是否有edge，有则是1
       - 无向图只需要上三角
       - 有向图同样可以表示，有edge标1，没有标0
       - weight也可以表示，不用0，1，直接用weight val
       - 缺点：一般来说，每个node只有很有限的neighs，所以这个matrix很sparse
     - 使用Adjacent linked list
       - 每个linked list的head是当前node，后面接的所有node就是neighs，解决了matrix的稀疏问题，这里只抽出了neighs
       - 可以表示有向和无向
       - 同样可以表示weight，把后面的graph node wrap成有权重的
       - 缺点：要get neighs最差要遍历整个linked list，其实这个是第一个表示方法的简化版本
   - 如何遍历graph？
     - 有多少个不连通的graph，就要多少个node。选这个区域代表，unifind
     - 同时，如果是有向无环图，需要入度为0的node来遍历，topological sort ；无向图任意node都可以。想象tree，不给root无法遍历完整个tree
   - Directed Acyclic Graph (DAG) 有向无环图
     - e.g. tree是DAG
   - 
## Q1 Kth smallest to largest element in an unsorted array (L215)
1. Description
   - 找到Kth smallest这个值
2. Clarification
   - kth smallest?如果定义大小比较
3. Follow up
   - Q1.1 Smallest K elements in unsorted array。输出可以要求sorted和unsorted
     - S1，输出前k直接就是sorted
     - S2，输出前k不是sorted，要sorted话，就花费klogk再sort一次，这里时间花费是constant，only depend on k
     - S3，poll出的就是sort好的前k
     - S4，loop完，按顺序poll出Max heap中的所有就是sort好的前k
### S1
1. Ideas：
   - 调用Arrays.sort
### S2
1. Ideas：
   - Quick selection: Quick partition + binary search 思想
     - 类似quick sort中的partition，选一个pivot，小的全放pivot左边，大的全丢到pivot右边
     - 由于找第k小，如果pivot正好位于index k-1，则此时的pivot就是第k小的
     - 如果pivot的index大于k-1，说明k-1在pivot左边，则在左半边选pivot，以此类推
     - 如果pivot的index小于k-1，说明k-1在pivot右边，则在右半边选pivot，以此类推
2. Comments:
   - 类似quick sort中的partition，只不过每次都类似binary search只保留一边再继续，这个过程就是quick selection。
   - 时间复杂度：
     - 最好情况：即一开始就选对pivot，即选到的pivot位于k-1，但是由于要知道pivot在k-1，我们需要遍历左半边和右半边才能知道位于k-1，因此是O(n)
     - 最差情况：找第1个小的，结果每次都找到是剩下的最大的，每次都遍历所有做swap，即: n + n-1 + n-2 + ... + 1 ~ O(n2)
     - 平均情况：即每次选的pivot比较好，都选到了中间，只留一半化为把n size问题转换成一个n/2 size问题，时间复杂度O(n)
### S3
1. Ideas：
   - 使用n size的Min heap
     - 把所有element放进去，不断地poll k个，第k个即为想要的数
2. Comments:
   - 如何把n size的element一次性加入？
     - 一个一个加入：nlogn，n个logn次的insert
     - heapify the whole input array：O(n)
   - poll k 个，花费k个logn的poll操作
   - 时间复杂度：n+klogn=O(n)
   - 空间复杂度：O(n)，n size的heap
### S4
1. Ideas：
   - 使用k size的Max heap
     - heap中存有所有array中当前最小的k个element
     - 来了第n个数，丢到heap中，这k+1个最大的被挤出来，heap中依然有这遍历过n size中最小的k个
2. Comments:
   - 过程：
     - heapify first first k element，O(k)
     - 把剩下的以loop的方式一个个往heap里放，如果大于heap top的数，不放；如果小于heap top的数，把top poll出来，把这个数丢进去。由于剩下n-k个，如果运气不好所有都要进入这个k size的heap，每次procolate down要logk，所以是（n-k)logk
   - 时间复杂度：k + (n-k)logk = O(n)
   - 空间复杂度：O(n)
   - 这几个Solution相比，哪个好？
     - 当k接近n
       - S3时间近似nlogn，S4近似n，S4好
       - 空间复杂度：S2最好
     - 当n很大，或者streaming flow
       - 只能用S4做
### S5
1. Ideas：
   - 使用TreeSet，要clarify整个element没有重复才可以使用TreeSet
## Q2 top K frequency words in an Dictionary
1. Description
   - null
2. Clarification
   - 分三步：
     - 统计每个word的frequency
     - 对frequency进行sort，把前k个frequency找出来
     - 把找出来的frequency对应的word return
3. Follow up
   - null
### S1
1. Ideas：
   - Hashmap + min heap + object
   - hashmap用于统计
   - heap用于frequency排序
   - object则wrap frequency和word，用于在最后一步通过frequency定位到word
2. Comments:
   - 声明这个heap要改写override comparator中的compare function
   - 如何遍历hashmap？
     - loop所有的key：```for (Key key: map.keySet())```
     - loop所有的key value pair：```for (Entry entry: map.entrySet())```
     - 这里for loop中可以使用```:```进行遍历的class object都是implement iterator和其中的iterable
### S2
1. Ideas：
   - clarify frequency是否有重复则可以使用TreeSet和TreeMap代替heap做
### S3
1. Ideas：
   - 使用trie
2. Comments:
   - 当input特别大，hashmap放不下，可以使用trie
   - 单词长度有限，trie才能放得下
   - 更大的话，分布式的trie，把各个subtree放在不同的机器上
     - 对于整个trie的过程中，各个element的reference的内存地址对应于不同机器的内存地址
   - 当分布式内存放不下，看看一个硬盘放得下？
   - 放不下就是多个分布式硬盘，即map reduce
## Q3 Missing number (L268)
1. Description
   - 以0为初始，等差数列差为1，0, 1, 2, ...
2. Clarification
   - element的type是啥？
   - 是不是sort？sort或者unsorted
   - size？
3. Follow up
   - Q2.1 每个出现两次，有且只有一个出现一次
     - 可以使用hashset，每次看hashset里没有就放进去，有的话就把hashset里的删掉；最后剩在hashset里唯一的那个就是target。（同理hashmap也行）
     - OXR bit操作，两个相同就抵消。由于XOR满足交换律和结合律，所以把整个array中的数XOR连起来，相同的全部抵消，最后剩下的就是只出现一次的
     - S1同样可以，fast-1和fast双指针，两个以每次2步一起走，当fast-1和fast不一样时，发现了这个只出现一次的数
     - S2同样可以，由于出现两次，所以正常到达n时，n前面如果都是每个出现两次，则```array[n]/2 = array[(n+1)/2] = n // 2```，如果这不符合，说明前面有missing number，或者当前就是missing number。S3同理，分为符合和不符合，符合missing number在这个数的右边，不符合在这个数的左边
     - 数学方法也可以，求sum相减
   - Q2.2 每个出现m次，有n个出现k次
     - S1，S2，S3，S5不可以。
     - 如果element是数字，同时m为偶，k为奇，XOR可以；如果m是奇，k为偶，只能使用hashmap记录每个element的次数，第一遍遍历build hashmap，第二遍扫hashmap找到这个target
     - 如果不是数字，XOR也不行。所以最general的是hashmap直接统计
### S1
1. Ideas：
   - Sort，然后fast - 1, fast双指针遍历
   - fast - 1在0，fast在1，同步向后走，当```array[fast] - array[fast - 1] != 1```是，说明missing number是fast
2. Comments:
   - fast - 1的edge case
### S2
1. Ideas：
   - 以0为初始等差数列差为1即天然就是index
   - 直接check index，即有个counter从0开始，从左向右，不断比较```array[counter] == counter```，不等于说明missing了这个counter
2. Comments:
   - null
### S3
1. Ideas：
   - 在sort好后，missing number左边都是```counter[index] = index```，在missing number右边都是```counter[index] = index + 1```，所以可以用binary search
### S4
1. Ideas：
   - 使用hashset，遍历两遍整个array
   - 第一遍先把array中的数全部加到hashset中
   - 第二遍，从0到n-1，遍历hashset，看是否contains，直到不contains，即为missing number
2. Comments:
   - 能用hashset就用hashset，这里也可以用hashmap，不过用不到key value pair这个一一对应的关系
### S5
1. Ideas：
   - Math
   - 直接把这个n size的unsorted的array求个sum，再求等差数列差为1初始为0一共n个的sum，这两个sum一减就是答案
## Q4 Given two array array1[n] array2[m], find the common elements
1. Description
   - 两个array找common element
2. Clarification
   - sorted？
   - duplicate？是否需要记录duplicate
   - m和n的关系？谁大谁小？
3. Follow up
   - null
### S1
1. Ideas：
   - sort两个array
   - 两个指针分别从两个array从前往后走，遍历到相同时，记录到return的array中
   - 然后根据是否记录duplicate，如果不需要duplicate，用for loop跳过所有相同的当前的数，到达下一个，再继续比较
   - 这个过程的终止条件是两个array任一一个遍历完了为止
   - 时间复杂度：sort的mlogm + nlogn，和遍历的m+n，所以是mlogm + nlogn + m + n
### S2
1. Ideas：
   - 使用hashset，只有当两个array各自不存在duplicate value
   - 把array1的所有element丢到hashset
   - loop array2中的每个element，hashset constains说明array1也有，所以是common
2. Comments:
   - 时间复杂度：O(m+n)
   - hashset放m和n较小size的那个array，所以空间复杂度是O(min(m,n))
### S3
1. Ideas：
   - sort两个较长的那个，对短的每个element在sort好的长的上面做binary search寻找是否存在
2. Comments:
   - 时间复杂度：假设短的是m，长的是n，所以sort是nlogn，加上m个binary search于长的logn，所以是mlogn
   - 如果两个array都是sorted，没有sort的花费的话，就是比较后面的mlogn和m+n大小关系，即mlogn和m（1+n/m)，当n远远大于m时，mlogn好；当n较为接近m是，m+n好
## Q5 (L???)
1. Description
   - null
2. Clarification
   - null
3. Follow up
   - null
### S1
1. Ideas：
   - null
2. Comments:
   - null